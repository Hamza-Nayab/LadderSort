Case0 = Sorted
Case 1 = Random
Case 2 = End Insertion
Case 3 = Sorted Blocks
Case 4 = Few Unique and stable groups
Case 5 = Reverse
Case 6 = 95% sorted 5% Random
Case 7 = 10 unique elements at the end.

Best Cases:
1:
og/event compaction from Kafka (or sharded logs): each partition is time-sorted, a consumer reads partitions round-robin into one file, then you need a global time sort.

Multi-sensor/time-series fusion: each sensor stream is monotone in time; a recorder multiplexes samples round-robin; later you sort by timestamp.

Inverted-index / posting-list merges: per-shard lists are sorted by docID; batches get interleaved on write; final build does a global merge-sort.

Distributed ETL/warehouse coalesce: Spark/DB partitions emit locally sorted chunks; a writer interleaves them; final compaction sorts into one ordered table.

(The “push_back(-1)” mimics a late, out-of-order record—e.g., a log with an earlier timestamp arriving after the batch.)

2: Riffle two sorted halves by coin-flip
It models two already-sorted streams randomly interleaved (e.g., merging two database partitions or two sensor/log feeds); you just need a global re-sort.
Great for run-aware merges (LadderSort, mergesort/Timsort) and for testing recovery from a late out-of-order record (your push_back(-1) step).

3:Shuffled sorted blocks
The array is a concatenation of a few long, already-sorted blocks but in random block order. Long natural runs make Timsort shine (run detection + merging); LadderSort is fine but loses its edge as blocks get longer.



1) K-way round-robin interleave (small K)

Kafka/stream compaction across partitions. Each partition is time-sorted; a consumer multiplexes partitions round-robin into one file, later requiring a global sort by timestamp or key.

Multisensor fusion pipelines. Per-sensor readings are monotone in time; acquisition threads interleave samples round-robin; downstream analytics re-establish total order.

Search indexing across shards. Posting lists from many shards are each sorted by docID/term-pos; shard outputs are interleaved during build or incremental refresh and then globally merged.

Distributed ETL coalesce. Spark/Flume/Beam workers emit locally sorted micro-batches; the sink alternates among workers; warehouse load step performs a K-way merge into sorted tables.

Financial tick feeds. Venue-specific feeds are individually ordered; a normalizer alternates venues, producing interleaved ticks that must be re-sorted to a single market time line.

2) Riffle of two sorted halves (coin-flip interleave)

Levelled LSM compaction (adjacent levels). Two sorted runs (e.g., Lk and Lk+1) are merged; arrival/service jitter makes their contributions appear randomly interleaved.

Primary/replica log reconciliation. Two ordered logs (leader and follower) must be merged after a partition; events are already sorted within each log but interleaved across logs.

Dual-source data join. Two pre-sorted partitions (e.g., two DB shards after a split) are merged during rebalancing; per-shard order is preserved, cross-shard order is mixed.

Batch+delta consolidation. A large historical run and a smaller incremental run are each sorted by key; ingestion riffles them before a global re-sort/compaction step.

Two-camera or stereo telemetry. Each camera stream is time-sorted; frames arrive interleaved due to transport jitter and must be re-sequenced.

3) Shuffled sorted blocks (few long, already-sorted chunks)

Columnar file ingestion (Parquet/ORC). Workers produce sorted row-groups/stripes; completion is out-of-order, so the final file is a concatenation of long sorted blocks in random block order before final compaction.

External sort run assembly. An external sorter spills long, sorted runs to disk; when runs are read back or cached asynchronously, concatenation order can be shuffled prior to the final merge.

Time-segmented log archiving. Each segment (e.g., 5-minute window) is individually sorted; archival processes append segments as they finish, yielding a sequence of long sorted blocks in non-temporal order.

MapReduce/Shuffle outputs. Mappers emit per-partition runs that are internally sorted; reducers receive large sorted chunks from many mappers in arbitrary completion order.

HPC/analytics tiling. Per-tile computations write sorted results; the filesystem or job scheduler returns tiles in nondeterministic order, producing a shuffled concatenation of sorted tiles.

(In all cases, your “push_back(-1)” acts as a late, out-of-order record—common with stragglers, retries, or clock skew—forcing the algorithm to repair near-sorted inputs.)